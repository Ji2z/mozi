## 프로젝트에서 사용하는 외부 서비스 정보 문서 

: 소셜 인증, 포톤 클라우드, 코드 컴파일 등에 활용된 '외부 서비스' 가입 및 활용에 필요한 정보



#### 전체 목차

- AI data

- 환경설정

  1. Git clone TensorFlow Models repository
  2. [Protobuf 설치](https://github.com/protocolbuffers/protobuf/releases/tag/v3.17.3) (protoc-3.17.3-win64.zip)
  3. COCO API 설치
  4. [CUDA Toolkit 설치](https://developer.nvidia.com/cuda-11.2.2-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exenetwork)
  5.  [cuDNN](https://developer.nvidia.com/rdp/cudnn-archive) (cuDNN v8.1.0 (January 26th, 2021), for CUDA 11.0,11.1 and 11.2)
  6. Object Detection API 설치
  7. 환경 변수 설정
  8. 가상환경 생성
  9. 필요 라이브러리 설치
  10. 실행 테스트

- 참고 사이트 및 자료

  #### Real-time object detection in the browser using TensorFlow.js

  https://github.com/hugozanini/TFJS-object-detection

  https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html

  <img src = "/uploads/5d3fd16c20b7024cfa97f3ec15918b3f/kites_detections_output.jpg" width="50%" height="50%">

  [참고한 블로그](https://velog.io/@jwhan/Tensorflow2로-Custom-Object-Detecter-학습하기-1-설치#target-software-versions)

  [공식 튜토리얼](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html)

  



## AI data

<img src = "/uploads/38d7157356cf08c847871170a189872e/ai_hub.JPG" width="20%" height="20%">

https://aihub.or.kr/aidata/34145

홈페이지 가입 후, 상품 이미지 사용 신청 및 다운로드.

![ai_img](/uploads/fab4c2cf2943d52706eda9039d1e919f/ai_img.JPG)

- 데이터 셋명: 상품 이미지

- 데이터분야 : 비전

- 구축기관: 롯데정보통신

- 가공기관: 에이모

- 데이터 관련 문의처 

  - 담당자명 : 전시형(롯데정보통신)
  - 전화번호 : 02-2028-9010
  - 이메일 : sihyoung.jurn@lotte.net

  

- 구축년도 : 2020년

- 최종수정일자 : 2021.06.25

- 소개 :  물류창고, 무인 스토어 등에서 탐지, 식별 솔루션에 활용될 수 있는 상품 이미지 데이터

- 저작권 및 이용정책 : 본 데이터는 과학기술정보통신부가 주관하고 한국지능정보사회진흥원이 지원하는 '인공지능 학습용 데이터 구축사업'으로 구축된 데이터입니다. [[데이터 이용정책 상세보기\]](https://aihub.or.kr/intro/policy#policy-cont-1)

- 구축목적 : 소상공인 자동화 매장 구축을 위해 활용 가치가 높은 10,000 종 이상의 상품에 대해 데이터를 구축해서 다양한 상품 분류 서비스 개발에 활용될 목적으로 구축됨

- 활용 분야: 유통 매장 진열 상품을 분류하는 서비스, 선반, 셀프결제대 상품 인식하여 결제 하는 서비스, 결품 확인 서비스 등 활용 가능

- 이미지 구분

  - Pitch : 0, 30, 60
  - Roll : 0, 180, 270





## 환경 설정 관련 외부 서비스



| OS                            | Windows |
| ----------------------------- | ------- |
| Python                        | 3.9     |
| TensorFlow                    | 2.5.0   |
| CUDA Toolkit                  | 11.2    |
| CuDNN                         | 8.1.0   |
| ssd_mobilenet_v2_320x320_coco |         |



###### COCO API

```null
https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
```

###### CUDA

```
https://developer.nvidia.com/cuda-11.2.2-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exenetwork
```

###### cuDNN NVIDIA

```
https://developer.nvidia.com/rdp/cudnn-archive
```



Compute Capability : 7.5 (NVIDIA GeForce RTX 2060)

- 자신에게 맞는 숫자 확인하기 : https://developer.nvidia.com/cuda-gpus#compute





## <u>가상환경 설정</u>



### 1. Git clone TensorFlow Models repository

```bash
git clone <https://github.com/tensorflow/models.git>
```



### 2. [Protobuf 설치](https://github.com/protocolbuffers/protobuf/releases/tag/v3.17.3) (protoc-3.17.3-win64.zip)

1. 압축 풀어서 원하는 디렉토리에 저장한다 (예: C:\Program Files\Google Protobuf)

2. 시스템 변수에서 Path에 해당 경로를 추가해준다.

   ![환경변수](/uploads/ea8e7b1db63a9059b97fdddb2e7547b7/환경변수.png)

3. 앞에서 다운받은 models/research/ 경로에서 다음 커맨드를 실행한다.

   ```
    C:\SSAFY\MOZI\reserch>protoc object_detection/protos/*.proto --python_out=.   
    C:\SSAFY\MOZI\reserch>protoc --version
    libprotoc 3.17.3
   ```

4. 커맨드 실행 후 변경된 변수를 사용하기 위해 **반드시** 터미널을 새로 열기.

5. models/research/object_detection/protos에 pb2.py들이 생성된 것 확인



### 3. COCO API 설치

```bash
pip install cython
pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
```

![채채](/uploads/bbb835a9a39f7c8d59fd204fdc0f13df/채채.png)



### 4. [CUDA Toolkit 설치](https://developer.nvidia.com/cuda-11.2.2-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exenetwork)

- 사진

  <img src = "/uploads/e2b7511c1a2dabf351cb053f2c41ae6b/cuda.png" width="80%" height="80%">



### 5. [cuDNN](https://developer.nvidia.com/rdp/cudnn-archive) (cuDNN v8.1.0 (January 26th, 2021), for CUDA 11.0,11.1 and 11.2)

![library](/uploads/cb7bd5e7e7a178392c01ef6ba44a71df/library.png)

- cudnn-11.2-windows-x64-v8.1.0.77.zip의 bin, include, lib

  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2 폴더 안 같은 폴더에 넣기

  - 사진

    ![cuda_folder](/uploads/d87beadbc57e73fb88f1ad981d9ab372/cuda_folder.png)

- 환경 변수 확인하기

  ![환경변수2](/uploads/01bd455342b227a6fd4f31d0aed93a79/환경변수2)



### 6. Object Detection API 설치

- models/research/object_detection/packages/tf2/setup.py 파일을 models/research/ 로 복사

- models/research/ 에서

  ```bash
  python setup.py build
  python setup.py install
  ```



### 7. 환경 변수 설정

- 새로만들기 - 값은 본인값으로

![환경변수3](/uploads/d361f8a264170703986e1ac43109e8d1/환경변수3.png)

### 8. 가상환경 생성

```bash
conda create -n [이름] pip python=3.8
conda activate [이름]
pip install tensorflow
python
import tensorflow as tf
tf.__version__
```

![8가상환경생성](/uploads/fc0deafd46f70ae7375cdd0623eb14cb/8가상환경생성.png)

### 9. 필요 라이브러리 설치

[참고 블로그](https://musma.github.io/2019/02/15/tensorflow-on-windows.html)

```bash
pip install pillow
pip install lxml
pip install jupyter
pip install matplotlib
```

### 10.

```bash
## 순서
## research 폴더 아래에서 cmd창 열고 가상환경 [ conda activate 이름 ] 하고 실행

# 1. setup.py 있는 폴더에서
python -m pip install . 

# 2. 코코 깔기
pip install cython
conda install git -y
pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI

# 3. 업그레이드
pip install --ignore-installed --upgrade tensorflow-gpu
pip install --ignore-installed --upgrade tensorflow

# 4. 테스트
python object_detection\\builders\\model_builder_tf2_test.py
```

```
## 실행 명령어

- record
  python generate_tfrecord_v2.py -x images\train -l annotations/label_map.pbtxt -o annotations/train.record
  python generate_tfrecord_v2.py -x images\test -l annotations/label_map.pbtxt -o annotations/test.record

- train
  python model_main_tf2.py --model_dir=models/my_new_model --pipeline_config_path=models/my_new_model/pipeline.config
  python model_main_tf2.py --model_dir=models/my_ssd_mobilenet_v2 --pipeline_config_path=models/my_ssd_mobilenet_v2/pipeline.config

- export
  python exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_ssd_mobilenet_v2\pipeline.config --trained_checkpoint_dir .\models\my_ssd_mobilenet_v2\ --output_directory .\exported-models\my_model


```





### 폴더 구조

- https://junsik-hwang.tistory.com/43?category=819242

- https://ctkim.tistory.com/81

- https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#preparing-the-workspace

  

```
TensorFlow/
├─ addons/ (Optional)
│  └─ labelImg/
├─ models/
│  ├─ community/
│  ├─ official/
│  ├─ orbit/
│  ├─ research/
│  └─ ...
└─ workspace/
   └─ training_demo/
```

```
training_demo/
├─ annotations/
├─ exported-models/
├─ images/
│  ├─ test/
│  └─ train/
├─ models/
├─ pre-trained-models/
└─ README.md
```

```
research/object_detection/colab-tutorials
├─ .ipynb_checkpoints/
├─ my-model/
├─ test_images/
├─ label_map.pbtxt
└─ object_detection_tutorial.ipynb
```





